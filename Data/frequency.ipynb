{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying Corpora Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import json\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"modify according to your setup\"\"\"\n",
    "\n",
    "# model directory path\n",
    "program_dir = '../'\n",
    "\n",
    "# corpora directory path\n",
    "input_dir_path = Path(program_dir) / 'processed-corpora'\n",
    "if (not input_dir_path.is_dir()):\n",
    "    print(\"No processed corpora input directory found\")\n",
    "\n",
    "# phrases directory path\n",
    "phrases_dir_path = Path(program_dir) / 'phrases'\n",
    "if (not phrases_dir_path.is_dir()):\n",
    "    print(\"No phrases directory found\")\n",
    "\n",
    "# output directory path\n",
    "output_dir_path = Path(program_dir) / 'frequencies'\n",
    "output_dir_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('JCR', 47, 8), ('JM', 84, 45), ('JMR', 57, 18), ('MS', 39, 0)]\n"
     ]
    }
   ],
   "source": [
    "# journal data: tuples of format (journal name, # of volumes, volume # for 1981)\n",
    "journals = [(\"JCR\",47,0), (\"JM\",84,0), (\"JMR\",57,0), (\"MS\",39,0)]\n",
    "max_vols_after_1980 = 2020 - 1980 # 40\n",
    "\n",
    "# compute start volume nums for 1981\n",
    "# if start vol <= 0, that means joural doesn't have articles from that year\n",
    "# this is okay because we just won't find any matches for those vols when parsing files\n",
    "for i in range(len(journals)):\n",
    "    journal = journals[i]\n",
    "    name, volumes, _ = journal\n",
    "\n",
    "    vol_1981 = volumes - max_vols_after_1980 + 1\n",
    "    journals[i] = (name, volumes, vol_1981)\n",
    "\n",
    "print(journals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_year_to_index(yr, start_yr, end_yr, step):\n",
    "    \"\"\"Converts a year into a usable index for the word vector matrix.\n",
    "\n",
    "    Args:\n",
    "        yr:\n",
    "            The year of interest.\n",
    "        start_yr:\n",
    "            The first year, inclusive, of the corpora.\n",
    "        end_yr:\n",
    "            The last year, inclusive, of the corpora.\n",
    "        step:\n",
    "            How many years per timeslice.\n",
    "\n",
    "    Returns:\n",
    "        An integer index that represents the time slice containing the desired year in the word vector matrix.\n",
    "\n",
    "    Raises:\n",
    "        Exception:\n",
    "            The year specified is not contained in the year range of the corpora.\n",
    "    \"\"\"\n",
    "    if yr < start_yr or yr > end_yr:\n",
    "        raise Exception('Trying to access a year that is not in the corpora: ' + yr)\n",
    "    return (yr - start_yr) // step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_phrases_to_dict(input_file_name):\n",
    "    \"\"\"Takes in file with list of phrases separated by new lines (and each word separated by either spaces or hyphens).\n",
    "\n",
    "    e.g. Given list:\n",
    "        cross culture\n",
    "        cross-culture\n",
    "        decision making\n",
    "        in-store marketing\n",
    "\n",
    "    Example calls to resulting dictionary:\n",
    "        phrases[\"cross culture\"] = \"cross-culture\"\n",
    "        phrases[\"decision making\"] = \"decision-making\"\n",
    "        phrases[\"in store marketing\"] = \"in-store-marketing\"\n",
    "    \"\"\"\n",
    "    \n",
    "    phrases = {}\n",
    "    with open(input_file_name, 'r') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            line = line.lower()\n",
    "            phrases[line.replace(\"-\", \" \")] = line.replace(\" \", \"-\") # should disregard intra-word hyphens in phrases\n",
    "    return phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_phrase_list():\n",
    "    method_list_path = phrases_dir_path / 'Method.txt'    # replace with phrase list file names\n",
    "    topic_list_path = phrases_dir_path / 'Topic.txt'\n",
    "    autophrase_list_path = phrases_dir_path / 'autophrase_6147.txt'\n",
    "    if (not method_list_path.exists()) or (not topic_list_path.exists()) or (not autophrase_list_path.exists()):\n",
    "        print(\"Phrase lists not found, exiting early\")\n",
    "        return 1\n",
    "    \n",
    "    method_phrases = load_phrases_to_dict(method_list_path)    # Load method/topic list\n",
    "    topic_phrases = load_phrases_to_dict(topic_list_path)\n",
    "    autophrase_phrases = load_phrases_to_dict(autophrase_list_path)    # Load AutoPhrase list\n",
    "    \n",
    "    phrases = method_phrases    # Combine all into 1 list\n",
    "    phrases.update(topic_phrases)\n",
    "    phrases.update(autophrase_phrases)\n",
    "    \n",
    "    return list(phrases.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_vocab_list():\n",
    "    min_count = 20\n",
    "    print('- loading word id file')\n",
    "    with open(program_dir + 'dw2v-master/wordID_corpus.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.split(',') for line in lines]\n",
    "\n",
    "    lines = [line for line in lines if int(line[2]) >= min_count]\n",
    "    word_list = [line[1] for line in lines]\n",
    "    print('got full vocab list')\n",
    "    \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_freq_for_timeslice(timeslice, yrs_in_timeslice, phrase_list):\n",
    "    \"\"\"\n",
    "    Returns a frequency dictionary for a single time slice. Keys are journal names, and values are Counter objects.\n",
    "    \"\"\"\n",
    "    journal_freq_for_timeslice = {}\n",
    "#     {\"JCR\":defaultdict(int), \"JM\":defaultdict(int), \"JMR\":defaultdict(int), \"MS\":defaultdict(int)}\n",
    "    \n",
    "    for journal in journals:\n",
    "        name, volumes, vol_1981 = journal\n",
    "        start_vol = vol_1981 + timeslice * yrs_in_timeslice\n",
    "        \n",
    "        journal_dir_path = input_dir_path / name\n",
    "        \n",
    "        read_files = Path(journal_dir_path).glob('*.txt')   # List all files in directory\n",
    "        # Filter files with paths that match volume number start_vol and start_vol+1\n",
    "        read_files = [str(filename) for filename in read_files if int(filename.name.split(\"#\")[0]) in range(start_vol, start_vol + yrs_in_timeslice)]\n",
    "        read_files = sorted(read_files, key=lambda x:[int(c) if c.isdigit() else c for c in re.split(r'(\\d+)', x)])\n",
    "        \n",
    "        count = Counter()\n",
    "        for f in read_files:\n",
    "            with open(f, 'r') as infile:\n",
    "                line = infile.read()\n",
    "                words = line.split()\n",
    "                count.update(words)\n",
    "#             print(\"Counted word_list occurrences in file from\", name, \"directory:\", f)\n",
    "        journal_freq_for_timeslice[name] = Counter({key: val for key, val in count.items() if key in phrase_list})\n",
    "\n",
    "    return journal_freq_for_timeslice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_freq_for_timeslices(num_timeslices, yrs_in_timeslice, phrase_list):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of frequency dictionaries for each time slice. Keys are time slice indices, values are dictionaries of journal frequencies for that time slice.\n",
    "    \"\"\"\n",
    "    journal_freq_for_timeslices = {}\n",
    "    \n",
    "    for timeslice_i in range(num_timeslices):\n",
    "        journal_freq_for_timeslice = count_freq_for_timeslice(timeslice_i, yrs_in_timeslice, phrase_list)\n",
    "        journal_freq_for_timeslices[timeslice_i] = journal_freq_for_timeslice\n",
    "        \n",
    "        print(\"Got frequencies for period\", timeslice_i)\n",
    "    #     print(journal_freq_for_timeslice)\n",
    "\n",
    "    return journal_freq_for_timeslices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq_across_timeslices(journal_freq_for_timeslices):\n",
    "    \"\"\"\n",
    "    Returns a frequency dictionary for all time slices summed together. Keys are time slice indices, values are Counter objects.\n",
    "    \"\"\"\n",
    "    num_timeslices = len(journal_freq_for_timeslices)\n",
    "    journal_freq_across_timeslices = {\"JCR\":Counter(), \"JM\":Counter(), \"JMR\":Counter(), \"MS\":Counter()}\n",
    "    \n",
    "    for timeslice_i in range(num_timeslices):\n",
    "        journal_freq_for_timeslice = journal_freq_for_timeslices[timeslice_i]\n",
    "\n",
    "        journal_freq_across_timeslices[\"JCR\"] += journal_freq_for_timeslice[\"JCR\"]\n",
    "        journal_freq_across_timeslices[\"JM\"] += journal_freq_for_timeslice[\"JM\"]\n",
    "        journal_freq_across_timeslices[\"JMR\"] += journal_freq_for_timeslice[\"JMR\"]\n",
    "        journal_freq_across_timeslices[\"MS\"] += journal_freq_for_timeslice[\"MS\"]\n",
    "\n",
    "    return journal_freq_across_timeslices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- loading word id file\n",
      "got full vocab list\n",
      "39354\n"
     ]
    }
   ],
   "source": [
    "start_yr = 1981 # the first year of the corpora\n",
    "end_yr = 2020 # the last year of the corpora\n",
    "step = 2 # how many years per time slice\n",
    "num_timeslices = (end_yr - start_yr + 1) // step\n",
    "timeslice_yrs = range(start_yr, end_yr+1, step) # years 1981 to 2020 inclusive\n",
    "\n",
    "phrase_list = get_phrase_list()\n",
    "# print(phrase_list)\n",
    "full_vocab_list = get_full_vocab_list()\n",
    "print(len(full_vocab_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program - Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save + Load File Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count frequencies in corpora - can skip cell below if there are already frequency files saved!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got frequencies for period 0\n",
      "Got frequencies for period 1\n",
      "Got frequencies for period 2\n",
      "Got frequencies for period 3\n",
      "Got frequencies for period 4\n",
      "Got frequencies for period 5\n",
      "Got frequencies for period 6\n",
      "Got frequencies for period 7\n",
      "Got frequencies for period 8\n",
      "Got frequencies for period 9\n",
      "Got frequencies for period 10\n",
      "Got frequencies for period 11\n",
      "Got frequencies for period 12\n",
      "Got frequencies for period 13\n",
      "Got frequencies for period 14\n",
      "Got frequencies for period 15\n",
      "Got frequencies for period 16\n",
      "Got frequencies for period 17\n",
      "Got frequencies for period 18\n",
      "Got frequencies for period 19\n"
     ]
    }
   ],
   "source": [
    "# Find frequencies for each time slice and save file\n",
    "journal_freq_for_timeslices = count_freq_for_timeslices(num_timeslices, step, full_vocab_list)\n",
    "\n",
    "freq_savefile = output_dir_path / 'journal_freq_for_timeslices.p'\n",
    "pickle.dump(journal_freq_for_timeslices, open(freq_savefile, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Sum frequencies across all time slices and save file\n",
    "journal_freq_across_timeslices = count_freq_across_timeslices(journal_freq_for_timeslices)\n",
    "\n",
    "freq_savefile = output_dir_path / 'journal_freq_across_timeslices.p'\n",
    "pickle.dump(journal_freq_across_timeslices, open(freq_savefile, 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load journal frequencies from pre-saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal frequencies for individual timeslices loaded succesfully\n",
      "journal frequencies across summed timeslices loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "freq_savefile = output_dir_path / 'journal_freq_for_timeslices.p'\n",
    "try:\n",
    "    journal_freq_for_timeslices = pickle.load(open(freq_savefile, 'rb'))\n",
    "    print(\"journal frequencies for individual timeslices loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load frequencies\")\n",
    "    \n",
    "freq_savefile = output_dir_path / 'journal_freq_across_timeslices.p'\n",
    "try:\n",
    "    journal_freq_across_timeslices = pickle.load(open(freq_savefile, 'rb'))\n",
    "    print(\"journal frequencies across summed timeslices loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate and validate journal frequencies by period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies for period 0, years 1981 - 1982\n",
      "12\n",
      "1\n",
      "top 15 most frequent in JCR: [('choice', 1058), ('brand', 911), ('advertising', 776), ('preference', 493), ('attitude', 412), ('memory', 395), ('learning', 386), ('attention', 358), ('satisfaction', 337), ('consumer-behavior', 315), ('affect', 310), ('decision-making', 302), ('leisure', 292), ('knowledge', 258), ('information-processing', 245)]\n",
      "top 15 most frequent in MS: [('brand', 169), ('advertising', 144), ('regression', 62), ('survey', 58), ('maximum-likelihood', 53), ('pricing', 51), ('choice', 48), ('anova', 48), ('network', 45), ('market-share', 44), ('experience', 42), ('preference', 41), ('repeat-purchase', 37), ('decision-support', 35), ('explanatory-variables', 34)]\n",
      "Frequencies for period 1, years 1983 - 1984\n",
      "7\n",
      "15\n",
      "top 15 most frequent in JCR: [('brand', 1299), ('choice', 1166), ('involvement', 614), ('advertising', 611), ('communication', 463), ('attitude', 411), ('consumer-behavior', 334), ('learning', 317), ('knowledge', 313), ('memory', 268), ('preference', 267), ('decision-making', 265), ('affect', 238), ('experience', 231), ('attention', 203)]\n",
      "top 15 most frequent in MS: [('brand', 962), ('advertising', 806), ('choice', 600), ('preference', 241), ('memory', 217), ('market-share', 208), ('pricing', 155), ('brand-choice', 148), ('experience', 122), ('a-model', 101), ('promotions', 100), ('learning', 91), ('variety-seeking', 87), ('management-science', 83), ('regression', 83)]\n",
      "Frequencies for period 2, years 1985 - 1986\n",
      "7\n",
      "38\n",
      "top 15 most frequent in JCR: [('brand', 1285), ('memory', 1069), ('advertising', 884), ('knowledge', 843), ('choice', 728), ('attitude', 703), ('affect', 584), ('imagery', 565), ('learning', 494), ('attention', 472), ('consumer-behavior', 430), ('involvement', 416), ('preference', 362), ('experience', 355), ('social-psychology', 340)]\n",
      "top 15 most frequent in MS: [('choice', 648), ('advertising', 529), ('brand', 415), ('preference', 345), ('market-share', 147), ('pricing', 142), ('marketing-science', 110), ('regression', 105), ('conjoint-analysis', 102), ('services', 100), ('brand-choice', 87), ('learning', 76), ('response-function', 76), ('survey', 70), ('management-science', 68)]\n",
      "Frequencies for period 3, years 1987 - 1988\n",
      "5\n",
      "30\n",
      "top 15 most frequent in JCR: [('brand', 1817), ('choice', 1525), ('advertising', 1162), ('knowledge', 756), ('memory', 722), ('involvement', 632), ('attitude', 543), ('consumer-behavior', 375), ('affect', 339), ('attention', 328), ('learning', 306), ('communication', 278), ('social-psychology', 271), ('goals', 253), ('preference', 252)]\n",
      "top 15 most frequent in MS: [('advertising', 930), ('choice', 625), ('brand', 615), ('market-share', 311), ('marketing-mix', 239), ('promotions', 239), ('regression', 172), ('pricing', 170), ('marketing-science', 150), ('product-line', 115), ('preference', 107), ('market-shares', 101), ('nash-equilibrium', 101), ('conjoint-analysis', 87), ('experience', 83)]\n",
      "Frequencies for period 4, years 1989 - 1990\n",
      "7\n",
      "16\n",
      "top 15 most frequent in JCR: [('brand', 1670), ('advertising', 1083), ('choice', 1039), ('attitude', 723), ('memory', 589), ('experience', 479), ('affect', 472), ('knowledge', 399), ('preference', 345), ('consumer-behavior', 336), ('attention', 303), ('social-psychology', 296), ('motivation', 244), ('involvement', 219), ('schema', 219)]\n",
      "top 15 most frequent in MS: [('brand', 975), ('advertising', 615), ('choice', 540), ('market-share', 269), ('preference', 229), ('sales-force', 223), ('marketing-science', 156), ('services', 107), ('affect', 106), ('promotions', 105), ('communication', 100), ('variety-seeking', 92), ('a-model', 90), ('pricing', 82), ('experience', 78)]\n",
      "Frequencies for period 5, years 1991 - 1992\n",
      "10\n",
      "26\n",
      "top 15 most frequent in JCR: [('brand', 2355), ('attitude', 1039), ('advertising', 977), ('choice', 761), ('involvement', 725), ('memory', 712), ('knowledge', 614), ('experience', 590), ('consumer-behavior', 492), ('affect', 486), ('attention', 392), ('social-psychology', 296), ('learning', 283), ('persuasion', 283), ('satisfaction', 281)]\n",
      "top 15 most frequent in MS: [('brand', 2039), ('choice', 670), ('advertising', 647), ('market-share', 287), ('marketing-science', 250), ('brand-loyalty', 250), ('loyalty', 231), ('promotions', 227), ('brand-choice', 211), ('preference', 160), ('variety-seeking', 143), ('market-shares', 112), ('logit-model', 107), ('a-model', 107), ('pricing', 101)]\n",
      "Frequencies for period 6, years 1993 - 1994\n",
      "2\n",
      "26\n",
      "top 15 most frequent in JCR: [('brand', 1865), ('advertising', 1766), ('affect', 1236), ('experience', 1147), ('knowledge', 1070), ('choice', 920), ('memory', 787), ('persuasion', 785), ('attitude', 750), ('satisfaction', 712), ('involvement', 584), ('attention', 413), ('motivation', 407), ('preference', 351), ('social-psychology', 334)]\n",
      "top 15 most frequent in MS: [('brand', 1399), ('choice', 611), ('advertising', 543), ('market-share', 417), ('satisfaction', 331), ('brand-equity', 243), ('marketing-science', 229), ('promotions', 190), ('variety-seeking', 167), ('preference', 161), ('brand-choice', 159), ('customer-satisfaction', 151), ('affect', 136), ('a-model', 127), ('regression', 126)]\n",
      "Frequencies for period 7, years 1995 - 1996\n",
      "2\n",
      "43\n",
      "top 15 most frequent in JCR: [('brand', 809), ('choice', 713), ('knowledge', 700), ('experience', 474), ('advertising', 457), ('affect', 433), ('persuasion', 370), ('memory', 343), ('attitude', 329), ('learning', 272), ('involvement', 221), ('attention', 206), ('materialism', 189), ('schema', 189), ('preference', 186)]\n",
      "top 15 most frequent in MS: [('brand', 2147), ('advertising', 881), ('choice', 676), ('marketing-science', 617), ('promotions', 392), ('market-share', 314), ('brand-choice', 305), ('preference', 209), ('pricing', 201), ('loyalty', 176), ('technology', 174), ('brand-loyalty', 162), ('marketing-mix', 139), ('long-run', 137), ('affect', 121)]\n",
      "Frequencies for period 8, years 1997 - 1998\n",
      "0\n",
      "17\n",
      "top 15 most frequent in JCR: [('choice', 913), ('memory', 522), ('brand', 334), ('experience', 330), ('advertising', 328), ('attention', 261), ('preference', 226), ('cognition', 215), ('knowledge', 203), ('technology', 190), ('affect', 182), ('decision-making', 160), ('involvement', 155), ('goals', 128), ('emotion', 125)]\n",
      "top 15 most frequent in MS: [('brand', 946), ('marketing-science', 892), ('choice', 704), ('advertising', 616), ('satisfaction', 369), ('pricing', 358), ('product-line', 323), ('customer-satisfaction', 242), ('marketing-mix', 216), ('experience', 191), ('services', 179), ('a-model', 153), ('brand-equity', 148), ('preference', 136), ('parameter-estimates', 134)]\n",
      "Frequencies for period 9, years 1999 - 2000\n",
      "0\n",
      "45\n",
      "top 15 most frequent in JCR: [('brand', 2315), ('choice', 1221), ('advertising', 753), ('knowledge', 687), ('preference', 647), ('satisfaction', 545), ('memory', 532), ('persuasion', 464), ('experience', 450), ('affect', 393), ('learning', 278), ('motivation', 236), ('false-positive', 235), ('goals', 209), ('attention', 209)]\n",
      "top 15 most frequent in MS: [('brand', 1577), ('marketing-science', 1030), ('advertising', 874), ('pricing', 770), ('choice', 592), ('promotions', 341), ('experience', 319), ('internet', 252), ('market-share', 222), ('preference', 212), ('memory', 211), ('affect', 194), ('decision-making', 188), ('long-term', 170), ('attention', 157)]\n",
      "Frequencies for period 10, years 2001 - 2002\n",
      "1\n",
      "43\n",
      "top 15 most frequent in JCR: [('brand', 1551), ('choice', 1184), ('experience', 958), ('memory', 575), ('affect', 519), ('preference', 483), ('learning', 444), ('knowledge', 435), ('attitude', 371), ('advertising', 328), ('attention', 284), ('goals', 264), ('motivation', 246), ('anova', 222), ('materialism', 198)]\n",
      "top 15 most frequent in MS: [('marketing-science', 1202), ('brand', 604), ('pricing', 522), ('advertising', 485), ('choice', 408), ('promotions', 298), ('affect', 192), ('advance-selling', 189), ('management-science', 188), ('preference', 167), ('services', 165), ('market-share', 135), ('a-model', 122), ('survey', 121), ('marginal-cost', 121)]\n",
      "Frequencies for period 11, years 2003 - 2004\n",
      "0\n",
      "74\n",
      "top 15 most frequent in JCR: [('brand', 2774), ('choice', 1685), ('experience', 919), ('affect', 833), ('advertising', 613), ('goals', 552), ('preference', 551), ('memory', 531), ('attention', 493), ('knowledge', 450), ('persuasion', 440), ('involvement', 422), ('attitude', 316), ('motivation', 313), ('satisfaction', 273)]\n",
      "top 15 most frequent in MS: [('brand', 2331), ('advertising', 1350), ('marketing-science', 1346), ('choice', 982), ('pricing', 514), ('promotions', 344), ('market-share', 228), ('preference', 218), ('a-model', 215), ('learning', 213), ('experience', 205), ('new-products', 203), ('brand-choice', 192), ('affect', 184), ('parameter-estimates', 166)]\n",
      "Frequencies for period 12, years 2005 - 2006\n",
      "0\n",
      "83\n",
      "top 15 most frequent in JCR: [('brand', 2323), ('choice', 1502), ('affect', 947), ('attitude', 768), ('experience', 520), ('goals', 518), ('memory', 477), ('preference', 429), ('knowledge', 359), ('anova', 302), ('attention', 265), ('imagery', 229), ('advertising', 209), ('involvement', 205), ('satisfaction', 196)]\n",
      "top 15 most frequent in MS: [('advertising', 2966), ('brand', 2657), ('marketing-science', 1863), ('pricing', 1051), ('choice', 874), ('satisfaction', 825), ('technology', 510), ('preference', 494), ('customer-satisfaction', 477), ('market-share', 376), ('services', 333), ('loyalty', 308), ('innovation', 278), ('a-model', 277), ('affect', 264)]\n",
      "Frequencies for period 13, years 2007 - 2008\n",
      "4\n",
      "90\n",
      "top 15 most frequent in JCR: [('brand', 2561), ('choice', 2349), ('experience', 1408), ('goals', 1032), ('affect', 831), ('preference', 751), ('attention', 646), ('self-control', 585), ('learning', 572), ('attitude', 562), ('memory', 502), ('anova', 477), ('advertising', 431), ('knowledge', 411), ('motivation', 403)]\n",
      "top 15 most frequent in MS: [('brand', 3470), ('marketing-science', 2227), ('advertising', 1855), ('choice', 1251), ('pricing', 1145), ('wholesale-price', 556), ('preference', 539), ('promotions', 520), ('market-share', 480), ('retail-price', 414), ('affect', 400), ('network', 388), ('learning', 384), ('loyalty', 362), ('a-model', 333)]\n",
      "Frequencies for period 14, years 2009 - 2010\n",
      "2\n",
      "98\n",
      "top 15 most frequent in JCR: [('choice', 2930), ('brand', 1875), ('experience', 1434), ('self-control', 1250), ('affect', 880), ('goals', 781), ('learning', 627), ('motivation', 604), ('knowledge', 559), ('memory', 539), ('preference', 515), ('anova', 472), ('emotion', 461), ('attitude', 453), ('attention', 411)]\n",
      "top 15 most frequent in MS: [('advertising', 3132), ('brand', 2801), ('marketing-science', 2534), ('choice', 1554), ('preference', 993), ('pricing', 969), ('affect', 565), ('innovation', 535), ('internet', 530), ('promotions', 463), ('technology', 435), ('a-model', 430), ('experience', 379), ('learning', 378), ('information-acquisition', 362)]\n",
      "Frequencies for period 15, years 2011 - 2012\n",
      "0\n",
      "131\n",
      "top 15 most frequent in JCR: [('choice', 3019), ('brand', 2583), ('experience', 1796), ('goals', 1262), ('affect', 1178), ('preference', 1102), ('self-control', 961), ('attention', 841), ('knowledge', 744), ('motivation', 695), ('commitment', 568), ('anova', 535), ('memory', 503), ('satisfaction', 476), ('attitude', 358)]\n",
      "top 15 most frequent in MS: [('marketing-science', 2222), ('brand', 2191), ('advertising', 2066), ('choice', 1430), ('network', 881), ('pricing', 694), ('learning', 689), ('nutrition', 535), ('technology', 520), ('internet', 514), ('affect', 460), ('preference', 450), ('knowledge', 422), ('survey', 410), ('innovation', 359)]\n",
      "Frequencies for period 16, years 2013 - 2014\n",
      "0\n",
      "96\n",
      "top 15 most frequent in JCR: [('brand', 2980), ('choice', 2314), ('experience', 1939), ('affect', 1246), ('preference', 864), ('attention', 852), ('goals', 789), ('self-control', 768), ('satisfaction', 563), ('advertising', 550), ('emotion', 547), ('anova', 534), ('perception', 506), ('materialism', 420), ('memory', 411)]\n",
      "top 15 most frequent in MS: [('brand', 2685), ('advertising', 2237), ('marketing-science', 2210), ('choice', 1104), ('learning', 957), ('pricing', 848), ('experience', 653), ('affect', 423), ('network', 392), ('preference', 361), ('communication', 343), ('survey', 300), ('a-model', 299), ('market-share', 263), ('technology', 245)]\n",
      "Frequencies for period 17, years 2015 - 2016\n",
      "0\n",
      "78\n",
      "top 15 most frequent in JCR: [('brand', 1970), ('choice', 1461), ('experience', 1065), ('preference', 944), ('attention', 708), ('persuasion', 581), ('goals', 528), ('knowledge', 526), ('emotion', 512), ('affect', 492), ('motivation', 468), ('anova', 412), ('attitude', 383), ('memory', 361), ('self-control', 358)]\n",
      "top 15 most frequent in MS: [('marketing-science', 2213), ('advertising', 1831), ('choice', 1444), ('brand', 1238), ('network', 798), ('learning', 735), ('pricing', 709), ('innovation', 464), ('survey', 446), ('affect', 423), ('preference', 401), ('search-engine', 382), ('knowledge', 381), ('experience', 369), ('wholesale-price', 326)]\n",
      "Frequencies for period 18, years 2017 - 2018\n",
      "0\n",
      "50\n",
      "top 15 most frequent in JCR: [('brand', 2661), ('choice', 2613), ('experience', 2079), ('preference', 1316), ('attention', 977), ('affect', 975), ('mediation', 857), ('motivation', 766), ('goals', 765), ('memory', 742), ('aesthetics', 718), ('knowledge', 647), ('survey', 589), ('mturk', 531), ('perception', 519)]\n",
      "top 15 most frequent in MS: [('marketing-science', 2250), ('advertising', 2173), ('brand', 2153), ('pricing', 1081), ('choice', 947), ('network', 480), ('communication', 465), ('promotions', 350), ('memory', 342), ('preference', 342), ('market-share', 338), ('product-line', 338), ('learning', 332), ('brand-equity', 311), ('innovation', 297)]\n",
      "Frequencies for period 19, years 2019 - 2020\n",
      "1\n",
      "52\n",
      "top 15 most frequent in JCR: [('brand', 1214), ('choice', 1065), ('experience', 646), ('attention', 563), ('motivation', 510), ('self-esteem', 449), ('preference', 442), ('memory', 306), ('affect', 304), ('emotion', 294), ('survey', 269), ('goals', 239), ('anova', 235), ('mturk', 216), ('attitude', 199)]\n",
      "top 15 most frequent in MS: [('advertising', 2918), ('marketing-science', 1924), ('choice', 1145), ('brand', 1120), ('pricing', 892), ('learning', 809), ('preference', 480), ('affect', 433), ('technology', 348), ('regression', 293), ('knowledge', 272), ('survey', 250), ('experience', 236), ('network', 234), ('high-quality', 227)]\n"
     ]
    }
   ],
   "source": [
    "for yr in timeslice_yrs:\n",
    "    timeslice_i = convert_year_to_index(yr, start_yr, end_yr, step)\n",
    "    journal_freq_for_timeslice = journal_freq_for_timeslices[timeslice_i]\n",
    "\n",
    "    print(\"Frequencies for period\", str(timeslice_i) + \", years\", yr, \"-\", yr+step-1)\n",
    "#     print(journal_freq_for_timeslice)\n",
    "    JCR_freq = journal_freq_for_timeslice[\"JCR\"]\n",
    "    MS_freq = journal_freq_for_timeslice[\"MS\"]\n",
    "    \n",
    "    print(JCR_freq[\"econometrics\"])\n",
    "    print(MS_freq[\"econometrics\"])\n",
    "    top_n = 15\n",
    "    print(\"top\", top_n, \"most frequent in JCR:\", JCR_freq.most_common(top_n))\n",
    "    print(\"top\", top_n, \"most frequent in MS:\", MS_freq.most_common(top_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at journal frequencies across all time periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 15 most frequent in JCR across all timeslices: [('brand', 37152), ('choice', 30166), ('experience', 17284), ('affect', 12878), ('advertising', 11767), ('memory', 10886), ('preference', 10705), ('knowledge', 10431), ('attitude', 9287), ('attention', 9185), ('goals', 8154), ('motivation', 6384), ('learning', 5613), ('involvement', 5494), ('satisfaction', 5292)]\n",
      "top 15 most frequent in MS across all timeslices: [('brand', 32494), ('advertising', 27598), ('marketing-science', 23518), ('choice', 16853), ('pricing', 10553), ('preference', 6286), ('learning', 5149), ('market-share', 5107), ('promotions', 4618), ('affect', 4340), ('experience', 4124), ('network', 4085), ('technology', 3674), ('a-model', 3624), ('survey', 3104)]\n"
     ]
    }
   ],
   "source": [
    "top_n = 15\n",
    "print(\"top\", top_n, \"most frequent in JCR across all timeslices:\", journal_freq_across_timeslices[\"JCR\"].most_common(top_n))\n",
    "print(\"top\", top_n, \"most frequent in MS across all timeslices:\", journal_freq_across_timeslices[\"MS\"].most_common(top_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program - Ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save + Load File Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate JCR/MS ratios - can skip cell below if there is already a file saved!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find JCR to MS ratios for each word in each timeslice\n",
    "ratios_for_timeslices = {}\n",
    "\n",
    "for yr in timeslice_yrs:\n",
    "    timeslice_i = convert_year_to_index(yr, start_yr, end_yr, step)\n",
    "    journal_freq_for_timeslice = journal_freq_for_timeslices[timeslice_i]\n",
    "    \n",
    "    JCR_freq = journal_freq_for_timeslice[\"JCR\"]\n",
    "    MS_freq = journal_freq_for_timeslice[\"MS\"]\n",
    "    \n",
    "    ratios = {}\n",
    "    for phrase in phrase_list:\n",
    "        JCR_phrase_freq = JCR_freq[phrase]\n",
    "        MS_phrase_freq = MS_freq[phrase]\n",
    "        \n",
    "        # if the word has 0 occurrence in either journal, set to 0 (will end up in middle of list)\n",
    "        if (JCR_phrase_freq == 0 and MS_phrase_freq == 0):\n",
    "            ratios[phrase] = 0\n",
    "        # if the word has 0 occurrence in MS, set to 1 * JCR freq (most freq in JCR will end up at top of list)\n",
    "        elif MS_phrase_freq == 0:\n",
    "            ratios[phrase] = JCR_phrase_freq\n",
    "        # if the word has 0 occurrence in JCR, set to -1 * MS freq (most freq in MS will end up at bottom of list)\n",
    "        elif JCR_phrase_freq == 0:\n",
    "            ratios[phrase] = -1 * MS_phrase_freq\n",
    "        else:\n",
    "            ratios[phrase] = JCR_phrase_freq / MS_phrase_freq\n",
    "    \n",
    "    ratios_for_timeslices[timeslice_i] = ratios\n",
    "\n",
    "# Save into file\n",
    "ratios_savefile = output_dir_path / 'ratios_for_timeslices.p'\n",
    "pickle.dump(ratios_for_timeslices, open(ratios_savefile, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# find JCR to MS ratios for each word in all timeslices\n",
    "ratios_across_timeslices = {}\n",
    "\n",
    "for phrase in phrase_list:\n",
    "    JCR_phrase_freq = journal_freq_across_timeslices[\"JCR\"][phrase]\n",
    "    MS_phrase_freq = journal_freq_across_timeslices[\"MS\"][phrase]\n",
    "\n",
    "    # if the word has 0 occurrence in either journal, set to 0 (will end up in middle of list)\n",
    "    if (JCR_phrase_freq == 0 and MS_phrase_freq == 0):\n",
    "        ratios_across_timeslices[phrase] = 0\n",
    "    # if the word has 0 occurrence in MS, set to 1 * JCR freq (most freq in JCR will end up at top of list)\n",
    "    elif MS_phrase_freq == 0:\n",
    "        ratios_across_timeslices[phrase] = JCR_phrase_freq\n",
    "    # if the word has 0 occurrence in JCR, set to -1 * MS freq (most freq in MS will end up at bottom of list)\n",
    "    elif JCR_phrase_freq == 0:\n",
    "        ratios_across_timeslices[phrase] = -1 * MS_phrase_freq\n",
    "    else:\n",
    "        ratios_across_timeslices[phrase] = JCR_phrase_freq / MS_phrase_freq\n",
    "\n",
    "# Save into file\n",
    "ratios_savefile = output_dir_path / 'ratios_across_timeslices.p'\n",
    "pickle.dump(ratios_across_timeslices, open(ratios_savefile, 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ratios from pre-saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratios for individual timeslices loaded succesfully\n",
      "ratios across timeslices loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "ratios_savefile = output_dir_path / 'ratios_for_timeslices.p'\n",
    "try:\n",
    "    ratios_for_timeslices = pickle.load(open(ratios_savefile, 'rb'))\n",
    "    print(\"ratios for individual timeslices loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load ratios\")\n",
    "    \n",
    "ratios_savefile = output_dir_path / 'ratios_across_timeslices.p'\n",
    "try:\n",
    "    ratios_across_timeslices = pickle.load(open(ratios_savefile, 'rb'))\n",
    "    print(\"ratios across timeslices loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine most quantitative and behavioral words in each time slice - can skip if already have ranked lists saved as files!\n",
    "We can retrieve the most behavioral and most quant words by looking at the highest ranked and lowest ranked ratios, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Period 0, years 1981-1982 ***\n",
      "Top 15 most behavioral words:\n",
      "leisure 292\n",
      "involvement 215.0\n",
      "energy-conservation 203.0\n",
      "energy-consumption 151\n",
      "product-information 148\n",
      "attribution 124\n",
      "mode-choice 102.0\n",
      "memory 98.75\n",
      "motivation 82\n",
      "united-states 82.0\n",
      "credit-cards 73\n",
      "social-class 71\n",
      "cognition 68\n",
      "status-quo 65\n",
      "public-policy 62\n",
      "\n",
      "Top 15 most quant words:\n",
      "decision-support -35\n",
      "piecewise-linear -22\n",
      "consumer-surplus -16\n",
      "innovation-diffusion -16\n",
      "customer-behavior -13\n",
      "technological-innovations -12\n",
      "binomial-distribution -8\n",
      "budget-allocation -8\n",
      "markov-process -8\n",
      "continuous-variables -7\n",
      "higher-dimensional -6\n",
      "mercedes-benz -6\n",
      "random-variables -6\n",
      "optimal-pricing -6\n",
      "input-variables -6\n",
      "\n",
      "*** Period 1, years 1983-1984 ***\n",
      "Top 15 most behavioral words:\n",
      "family-life 189\n",
      "social-class 171.0\n",
      "gift-giving 115\n",
      "classical-conditioning 104\n",
      "familiarity 96.5\n",
      "latent-class 96\n",
      "opinion-leaders 86\n",
      "attitude-change 70\n",
      "family-members 59.0\n",
      "lifestyle 56\n",
      "persuasion 54.333333333333336\n",
      "information-overload 53.0\n",
      "information-integration 53.0\n",
      "gift-exchange 48\n",
      "complaining 45\n",
      "\n",
      "Top 15 most quant words:\n",
      "nash-equilibrium -47\n",
      "quantity-discounts -45\n",
      "vertical-integration -42\n",
      "price-discrimination -37\n",
      "uniformly-distributed -30\n",
      "scanner-data -29\n",
      "quantity-discount -27\n",
      "wholesale-price -27\n",
      "learning-curve -25\n",
      "market-dynamics -22\n",
      "optimal-pricing -21\n",
      "planning-horizon -21\n",
      "marketing-activities -20\n",
      "firm-size -19\n",
      "profit-sharing -18\n",
      "\n",
      "*** Period 2, years 1985-1986 ***\n",
      "Top 15 most behavioral words:\n",
      "imagery 282.5\n",
      "materialism 196\n",
      "nutrition 159\n",
      "persuasion 154\n",
      "rituals 150\n",
      "emotion 128\n",
      "young-children 110\n",
      "cognition 109.0\n",
      "classical-conditioning 98\n",
      "lawrence-erlbaum 92.0\n",
      "product-information 92\n",
      "memory 89.08333333333333\n",
      "information-processing 88.33333333333333\n",
      "elderly-adults 85\n",
      "categorization 79.66666666666667\n",
      "\n",
      "Top 15 most quant words:\n",
      "latent-class -47\n",
      "transaction-costs -46\n",
      "multinomial-logit -42\n",
      "tree-structure -42\n",
      "transition-probabilities -40\n",
      "variety-seeking -38\n",
      "nested-logit -35\n",
      "transaction-cost -35\n",
      "productivity-growth -29\n",
      "total-factor-productivity -26\n",
      "probabilistic-choice -26\n",
      "rasch-model -26\n",
      "comparative-statics -22\n",
      "temporal-aggregation -22\n",
      "risk-tolerance -21\n",
      "\n",
      "*** Period 3, years 1987-1988 ***\n",
      "Top 15 most behavioral words:\n",
      "social-psychology 271\n",
      "reference-point 214\n",
      "satisfaction 168.0\n",
      "eeg 151\n",
      "persuasion 144\n",
      "mediation 138\n",
      "attribution 114\n",
      "cognition 114\n",
      "hong-kong 111\n",
      "prior-knowledge 94.0\n",
      "involvement 90.28571428571429\n",
      "memory 90.25\n",
      "emotion 88\n",
      "goals 84.33333333333333\n",
      "impulse-buying 84.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "nash-equilibrium -101\n",
      "marginal-cost -81\n",
      "quantity-discounts -69\n",
      "complaint-management -68\n",
      "covariance-matrix -46\n",
      "fixed-costs -44\n",
      "price-elasticity -42\n",
      "civil-society -40\n",
      "price-discrimination -40\n",
      "profit-maximizing -39\n",
      "quantity-discount -33\n",
      "end-users -30\n",
      "wholesale-price -29\n",
      "optimal-pricing -28\n",
      "vertical-integration -25\n",
      "\n",
      "*** Period 4, years 1989-1990 ***\n",
      "Top 15 most behavioral words:\n",
      "schema 219\n",
      "cognition 198\n",
      "ethnicity 184\n",
      "interview 114\n",
      "decision-criteria 77\n",
      "rituals 75\n",
      "attribute-values 73.0\n",
      "attitude 72.3\n",
      "service-quality 71\n",
      "ann-arbor 69\n",
      "memory 65.44444444444444\n",
      "impression-formation 65\n",
      "phenomenology 64\n",
      "mediation 63\n",
      "gift-giving 63\n",
      "\n",
      "Top 15 most quant words:\n",
      "response-function -58\n",
      "price-competition -37\n",
      "planning-horizon -36\n",
      "knowledge-base -31\n",
      "diffusion-models -28\n",
      "mixed-strategy -26\n",
      "risk-neutral -25\n",
      "product-sales -23\n",
      "skill-level -23\n",
      "profit-maximizing -21\n",
      "discount-rate -18\n",
      "service-levels -18\n",
      "marginal-utility -17\n",
      "wholesale-price -16\n",
      "market-equilibrium -15\n",
      "\n",
      "*** Period 5, years 1991-1992 ***\n",
      "Top 15 most behavioral words:\n",
      "social-psychology 296\n",
      "imagery 243\n",
      "attitude 173.16666666666666\n",
      "emotion 165\n",
      "prior-knowledge 152\n",
      "categorization 138\n",
      "schema 125.5\n",
      "involvement 120.83333333333333\n",
      "young-children 120\n",
      "soft-drink 106\n",
      "cognition 100\n",
      "persuasion 94.33333333333333\n",
      "attribution 91\n",
      "critical-theory 91\n",
      "price-premiums 91\n",
      "\n",
      "Top 15 most quant words:\n",
      "nested-logit -94\n",
      "unobserved-heterogeneity -77\n",
      "hazard-function -62\n",
      "wholesale-price -56\n",
      "steady-state -50\n",
      "explanatory-variables -42\n",
      "euclidean-space -38\n",
      "price-elasticities -34\n",
      "price-competition -29\n",
      "wholesale-prices -27\n",
      "holding-cost -22\n",
      "cost-function -21\n",
      "bidding-strategy -20\n",
      "discount-rate -20\n",
      "empirical-bayes -17\n",
      "\n",
      "*** Period 6, years 1993-1994 ***\n",
      "Top 15 most behavioral words:\n",
      "persuasion 785\n",
      "involvement 194.66666666666666\n",
      "critical-theory 171\n",
      "emotion 159\n",
      "materialism 156\n",
      "perceived-risk 136.0\n",
      "high-risk 123\n",
      "gift-giving 117\n",
      "social-psychology 111.33333333333333\n",
      "young-children 109\n",
      "information-acquisition 102\n",
      "schema 93\n",
      "product-information 93.0\n",
      "memory 87.44444444444444\n",
      "categorization 87.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "hazard-rate -75\n",
      "product-development -58\n",
      "price-competition -55\n",
      "holding-cost -42\n",
      "lorenz-curve -41\n",
      "paired-comparison -39\n",
      "subgame-perfect -38\n",
      "nash-equilibrium -36\n",
      "nested-logit -34\n",
      "wholesale-price -32\n",
      "random-effects -32\n",
      "unobserved-heterogeneity -29\n",
      "private-information -27\n",
      "diffusion-models -27\n",
      "incentive-compatible -26\n",
      "\n",
      "*** Period 7, years 1995-1996 ***\n",
      "Top 15 most behavioral words:\n",
      "persuasion 370.0\n",
      "materialism 189\n",
      "lifestyle 170.0\n",
      "imagery 167\n",
      "negative-emotions 117\n",
      "emotion 102\n",
      "attitude 82.25\n",
      "self-esteem 68\n",
      "impulse-buying 62\n",
      "impression-management 58\n",
      "anova 48.0\n",
      "cognition 48.0\n",
      "domain-specific 47\n",
      "ethnography 45\n",
      "visual-cues 41\n",
      "\n",
      "Top 15 most quant words:\n",
      "marketing-mix -139\n",
      "wholesale-price -110\n",
      "transaction-costs -97\n",
      "customer-expectations -61\n",
      "market-shares -56\n",
      "quantity-discount -49\n",
      "high-tech -45\n",
      "low-quality -43\n",
      "efficient-frontier -43\n",
      "cross-sectional -42\n",
      "transaction-cost -42\n",
      "response-function -39\n",
      "direct-marketing -38\n",
      "finite-mixture -38\n",
      "parameter-values -38\n",
      "\n",
      "*** Period 8, years 1997-1998 ***\n",
      "Top 15 most behavioral words:\n",
      "emotion 125\n",
      "aspiration-level 93\n",
      "attribute-based 87.0\n",
      "cultural-capital 84\n",
      "imagery 75\n",
      "memory 74.57142857142857\n",
      "exploratory-search 57\n",
      "involvement 51.666666666666664\n",
      "familiarity 51.0\n",
      "age-related 47\n",
      "ethnicity 45\n",
      "cognition 43.0\n",
      "high-school 43\n",
      "coping-strategies 43\n",
      "schema 39\n",
      "\n",
      "Top 15 most quant words:\n",
      "brand-equity -148\n",
      "wholesale-price -122\n",
      "finite-mixture -116\n",
      "neural-network -104\n",
      "neural-networks -92\n",
      "pricing-strategies -71\n",
      "retail-competition -70\n",
      "low-end -69\n",
      "operations-research -62\n",
      "response-function -60\n",
      "demographic-variables -59\n",
      "service-times -57\n",
      "service-provider -48\n",
      "diffusion-models -47\n",
      "marginal-cost -46\n",
      "\n",
      "*** Period 9, years 1999-2000 ***\n",
      "Top 15 most behavioral words:\n",
      "false-positive 235\n",
      "persuasion 154.66666666666666\n",
      "human-capital 101\n",
      "brand-communities 88\n",
      "consumer-socialization 76\n",
      "expert-judgments 63\n",
      "mental-imagery 57\n",
      "statistically-significant 55\n",
      "cultural-differences 52.0\n",
      "community-members 51\n",
      "open-ended 46.0\n",
      "cross-cultural 45.0\n",
      "significant-difference 43\n",
      "credit-card 42.0\n",
      "materialism 41\n",
      "\n",
      "Top 15 most quant words:\n",
      "price-elasticity -156\n",
      "price-elasticities -129\n",
      "pricing-strategies -96\n",
      "market-entry -76\n",
      "decision-aids -68\n",
      "information-goods -64\n",
      "search-engine -63\n",
      "online-shopping -60\n",
      "retail-price -52\n",
      "sales-representatives -51\n",
      "wholesale-price -50\n",
      "econometrics -45\n",
      "covariance-matrix -45\n",
      "electronic-shopping -42\n",
      "digital-tv -41\n",
      "\n",
      "*** Period 10, years 2001-2002 ***\n",
      "Top 15 most behavioral words:\n",
      "materialism 198\n",
      "emotion 163.0\n",
      "aesthetics 93.0\n",
      "memory 82.14285714285714\n",
      "social-presence 80\n",
      "statistically-significant 78\n",
      "foreign-currency 78\n",
      "mediation 76.0\n",
      "gift-giving 70\n",
      "emotional-contagion 68\n",
      "adaptive-learning 64\n",
      "perceived-risk 62\n",
      "affective-response 62\n",
      "schema 56\n",
      "exchange-rate 54.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "advance-selling -189\n",
      "management-science -188\n",
      "marginal-cost -121\n",
      "mixed-logit -109\n",
      "nash-equilibrium -64\n",
      "capacity-constraints -61\n",
      "mixed-strategy -61\n",
      "advance-purchase -58\n",
      "retail-competition -53\n",
      "graduate-school -51\n",
      "working-paper -50\n",
      "optimal-pricing -50\n",
      "capacity-constrained -50\n",
      "price-elasticities -49\n",
      "price-promotions -47\n",
      "\n",
      "*** Period 11, years 2003-2004 ***\n",
      "Top 15 most behavioral words:\n",
      "anova 267.0\n",
      "attribute-values 142.0\n",
      "schema 136\n",
      "cognitive-load 116\n",
      "social-identity 116.0\n",
      "materialism 105\n",
      "older-adults 105\n",
      "goal-orientation 100\n",
      "rituals 95\n",
      "affective-responses 93\n",
      "statistically-significant 90.0\n",
      "product-involvement 89\n",
      "creativity 82.0\n",
      "imagery 80\n",
      "imagination 80\n",
      "\n",
      "Top 15 most quant words:\n",
      "market-entry -127\n",
      "false-positive -121\n",
      "wholesale-price -96\n",
      "false-alarm -78\n",
      "choice-model -74\n",
      "conjoint-analysis -74\n",
      "econometrics -74\n",
      "pricing-strategy -70\n",
      "clickstream-data -66\n",
      "network-effects -66\n",
      "hierarchical-bayes -63\n",
      "pricing-strategies -60\n",
      "diffusion-models -58\n",
      "business-unit -54\n",
      "private-information -52\n",
      "\n",
      "*** Period 12, years 2005-2006 ***\n",
      "Top 15 most behavioral words:\n",
      "self-esteem 121\n",
      "cognitive-processes 73.0\n",
      "high-precision 66\n",
      "negative-emotions 66\n",
      "cognitive-load 64.0\n",
      "gift-giving 61\n",
      "imagery 57.25\n",
      "risk-perceptions 57\n",
      "affective-states 52\n",
      "cultural-differences 50.0\n",
      "self-control 44.333333333333336\n",
      "affective-responses 43.0\n",
      "older-adults 42\n",
      "low-precision 42\n",
      "mediation 39\n",
      "\n",
      "Top 15 most quant words:\n",
      "marketing-science -1863\n",
      "wholesale-price -201\n",
      "motion-picture -151\n",
      "working-paper -151\n",
      "product-review -150\n",
      "retail-price -128\n",
      "conjoint-analysis -114\n",
      "cheap-talk -111\n",
      "wholesale-prices -111\n",
      "key-words -106\n",
      "empirical-analysis -101\n",
      "price-adjustment -98\n",
      "management-science -96\n",
      "marketing-strategy -95\n",
      "econometrics -83\n",
      "\n",
      "*** Period 13, years 2007-2008 ***\n",
      "Top 15 most behavioral words:\n",
      "materialism 147\n",
      "self-esteem 138.5\n",
      "cognitive-load 100.0\n",
      "social-capital 94\n",
      "healthy-lifestyle 84\n",
      "negative-emotions 77.0\n",
      "nutrition 74.0\n",
      "moderation 71\n",
      "priming-effects 64\n",
      "family-members 62.0\n",
      "category-labels 62\n",
      "self-identity 59\n",
      "emotional-responses 57.0\n",
      "significant-difference 57\n",
      "goal-directed 51.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "wholesale-prices -300\n",
      "price-elasticity -152\n",
      "free-riding -144\n",
      "practice-prize -131\n",
      "key-words -128\n",
      "product-variety -119\n",
      "price-discrimination -116\n",
      "marginal-cost -116\n",
      "management-science -101\n",
      "nash-equilibrium -97\n",
      "nested-logit -91\n",
      "vertical-integration -88\n",
      "cross-validation -84\n",
      "pricing-strategies -83\n",
      "copyright-protection -82\n",
      "\n",
      "*** Period 14, years 2009-2010 ***\n",
      "Top 15 most behavioral words:\n",
      "run-length 164.0\n",
      "materialism 148\n",
      "cognitive-load 145\n",
      "self-esteem 142.0\n",
      "cultural-capital 129\n",
      "emotion 115.25\n",
      "process-oriented 99\n",
      "gift-giving 98.0\n",
      "affective-responses 97.0\n",
      "run-lengths 73\n",
      "step-size 70.0\n",
      "cover-story 70.0\n",
      "prior-knowledge 68.0\n",
      "significant-difference 68\n",
      "personality-traits 67\n",
      "\n",
      "Top 15 most quant words:\n",
      "information-acquisition -362\n",
      "wholesale-price -306\n",
      "price-competition -271\n",
      "click-fraud -227\n",
      "marginal-cost -225\n",
      "information-sharing -164\n",
      "search-engine -156\n",
      "key-words -154\n",
      "network-effects -152\n",
      "wholesale-prices -146\n",
      "mixed-logit -142\n",
      "sales-force -139\n",
      "observational-learning -138\n",
      "sponsored-links -131\n",
      "brand-value -122\n",
      "\n",
      "*** Period 15, years 2011-2012 ***\n",
      "Top 15 most behavioral words:\n",
      "anova 267.5\n",
      "affective-state 231\n",
      "charity 124\n",
      "high-confidence 114\n",
      "weight-loss 110\n",
      "imagery 87.5\n",
      "significant-difference 85\n",
      "negative-feedback 82.5\n",
      "self-identity 73\n",
      "physiological 71.0\n",
      "high-power 66.0\n",
      "confidence-interval 62\n",
      "self-esteem 60.666666666666664\n",
      "skin-cancer 57\n",
      "negative-emotions 57.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "open-source -217\n",
      "working-paper -203\n",
      "revenue-sharing -192\n",
      "network-effects -173\n",
      "associate-editor -172\n",
      "social-contagion -164\n",
      "text-mining -148\n",
      "search-advertising -139\n",
      "sponsored-search -133\n",
      "econometrics -131\n",
      "expected-utility -130\n",
      "posted-price -121\n",
      "marketing-activities -118\n",
      "degree-distribution -110\n",
      "log-likelihood -107\n",
      "\n",
      "*** Period 16, years 2013-2014 ***\n",
      "Top 15 most behavioral words:\n",
      "self-esteem 311.0\n",
      "anova 267.0\n",
      "self-control 256.0\n",
      "low-power 234\n",
      "cultural-capital 231\n",
      "high-power 224.0\n",
      "materialism 210.0\n",
      "social-identity 181.0\n",
      "confidence-interval 147\n",
      "mturk 138\n",
      "spatial-proximity 130\n",
      "tie-strength 122.0\n",
      "figurative-language 122\n",
      "significant-difference 120\n",
      "strong-ties 118\n",
      "\n",
      "Top 15 most quant words:\n",
      "direct-marketing -241\n",
      "wholesale-price -194\n",
      "search-advertising -177\n",
      "advance-selling -162\n",
      "sponsored-search -142\n",
      "wholesale-prices -140\n",
      "sales-force -125\n",
      "price-discrimination -115\n",
      "discrete-choice -112\n",
      "supplemental-material -110\n",
      "decision-aids -107\n",
      "product-differentiation -106\n",
      "cheap-talk -98\n",
      "marginal-cost -98\n",
      "econometrics -96\n",
      "\n",
      "*** Period 17, years 2015-2016 ***\n",
      "Top 15 most behavioral words:\n",
      "low-power 164.0\n",
      "user-ratings 151\n",
      "high-power 147.0\n",
      "mturk 122.5\n",
      "pilot-study 113.0\n",
      "materialism 109.0\n",
      "cognitive-load 91\n",
      "rituals 74.0\n",
      "moderated-mediation 71\n",
      "confidence-interval 70\n",
      "problem-solving 68.0\n",
      "self-esteem 65.66666666666667\n",
      "significant-difference 65.0\n",
      "resource-availability 57\n",
      "gift-giving 54.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "wholesale-price -326\n",
      "emerging-markets -195\n",
      "customer-centric -181\n",
      "search-advertising -180\n",
      "price-discrimination -171\n",
      "installed-base -168\n",
      "sponsored-search -133\n",
      "market-structure -133\n",
      "budget-constraint -118\n",
      "zip-code -109\n",
      "network-effects -105\n",
      "price-competition -103\n",
      "log-likelihood -103\n",
      "market-shares -96\n",
      "competitive-market -94\n",
      "\n",
      "*** Period 18, years 2017-2018 ***\n",
      "Top 15 most behavioral words:\n",
      "mediation 428.5\n",
      "aesthetics 359.0\n",
      "self-esteem 325.0\n",
      "psychological-ownership 284\n",
      "anova 248.0\n",
      "working-memory 206\n",
      "cognitive-load 199\n",
      "moderated-mediation 161\n",
      "significant-difference 118\n",
      "reference-point 116.0\n",
      "physiological 115.0\n",
      "individual-differences 110.0\n",
      "cultural-differences 105\n",
      "indirect-effects 105\n",
      "imagery 103.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "price-discrimination -208\n",
      "brand-value -175\n",
      "price-competition -164\n",
      "working-paper -150\n",
      "sponsored-search -135\n",
      "marginal-cost -126\n",
      "sequential-search -121\n",
      "wholesale-prices -116\n",
      "consumer-surplus -110\n",
      "equilibrium-prices -110\n",
      "business-cycle -108\n",
      "emerging-markets -100\n",
      "reserve-price -93\n",
      "advance-selling -88\n",
      "supplemental-material -87\n",
      "\n",
      "*** Period 19, years 2019-2020 ***\n",
      "Top 15 most behavioral words:\n",
      "self-esteem 449.0\n",
      "imagination 180\n",
      "intrinsic-motivation 161\n",
      "goal-attainment 140\n",
      "variety-seeking 111.0\n",
      "negative-emotions 107\n",
      "cognitive-load 100\n",
      "emotion 98.0\n",
      "cognitive-flexibility 92\n",
      "mental-imagery 91.0\n",
      "gift-giving 89.0\n",
      "undergraduate-students 62.0\n",
      "low-level 59.0\n",
      "anova 58.75\n",
      "significant-difference 58.0\n",
      "\n",
      "Top 15 most quant words:\n",
      "product-line -220\n",
      "google-news -181\n",
      "search-advertising -172\n",
      "hedge-fund -167\n",
      "working-paper -164\n",
      "price-discrimination -158\n",
      "human-capital -148\n",
      "mutual-fund -138\n",
      "online-advertising -111\n",
      "hedge-funds -110\n",
      "picture-quality -109\n",
      "wholesale-price -105\n",
      "machine-learning -99\n",
      "moral-hazard -99\n",
      "expert-opinion -86\n"
     ]
    }
   ],
   "source": [
    "for yr in timeslice_yrs:\n",
    "    timeslice_i = convert_year_to_index(yr, start_yr, end_yr, step)\n",
    "    ratios_for_timeslice = ratios_for_timeslices[timeslice_i]\n",
    "    \n",
    "    ranked_most_behavioral = OrderedDict(sorted(ratios_for_timeslice.items(), key=lambda kv: kv[1], reverse=True)) # JCR/MS larger = more behavioral\n",
    "    ranked_most_quant = OrderedDict(sorted(ratios_for_timeslice.items(), key=lambda kv: kv[1])) # JCR/MS smaller = more quant\n",
    "    \n",
    "    # Save ranked behavioral words\n",
    "    ranked_behavioral_pickle_savefile = output_dir_path / ('ranked_behavioral_for_timeslice_' + str(timeslice_i) + '.p')\n",
    "    pickle.dump(ranked_most_behavioral, open(ranked_behavioral_pickle_savefile, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    ranked_behavioral_txt_savefile = output_dir_path / ('ranked_behavioral_for_timeslice_' + str(timeslice_i) + '.txt')\n",
    "    with open(ranked_behavioral_txt_savefile, 'w') as outfile:\n",
    "        for key, value in ranked_most_behavioral.items():\n",
    "            outfile.write(str(key) + \": \" + str(value) + '\\n')\n",
    "    \n",
    "    # Save ranked quant words\n",
    "    ranked_quant_pickle_savefile = output_dir_path / ('ranked_quant_for_timeslice_' + str(timeslice_i) + '.p')\n",
    "    pickle.dump(ranked_most_quant, open(ranked_quant_pickle_savefile, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    ranked_quant_txt_savefile = output_dir_path / ('ranked_quant_for_timeslice_' + str(timeslice_i) + '.txt')\n",
    "    with open(ranked_quant_txt_savefile, 'w') as outfile:\n",
    "        for key, value in ranked_most_quant.items():\n",
    "            outfile.write(str(key) + \": \" + str(value) + '\\n')\n",
    "\n",
    "    print(\"\\n*** Period \" + str(timeslice_i) + \", years\", str(yr) + \"-\" + str(yr+step-1) + \" ***\")\n",
    "\n",
    "    top_n = 15\n",
    "    print(\"Top\", top_n, \"most behavioral words:\")\n",
    "    for phrase, ratio in list(ranked_most_behavioral.items())[:top_n]:\n",
    "        print(phrase, ratio)\n",
    "    print(\"\\nTop\", top_n, \"most quant words:\")\n",
    "    for phrase, ratio in list(ranked_most_quant.items())[:top_n]:\n",
    "        print(phrase, ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ranked behavioral + quant phrases from pre-saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked behavioral phrases for time slice 0 loaded succesfully\n",
      "Ranked quant phrases for time slice 0 loaded succesfully\n",
      "Ranked behavioral phrases for time slice 19 loaded succesfully\n",
      "Ranked quant phrases for time slice 19 loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "# Load ranked behavioral and quant words for time slice 0\n",
    "timeslice_i = 0\n",
    "ranked_behavioral_pickle_savefile = output_dir_path / ('ranked_behavioral_for_timeslice_' + str(timeslice_i) + '.p')\n",
    "try:\n",
    "    ranked_most_behavioral_0 = list(pickle.load(open(ranked_behavioral_pickle_savefile, 'rb')))\n",
    "    print(\"Ranked behavioral phrases for time slice \" + str(timeslice_i) + \" loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load ranked behavioral phrases for time slice \" + str(timeslice_i))\n",
    "    \n",
    "ranked_quant_pickle_savefile = output_dir_path / ('ranked_quant_for_timeslice_' + str(timeslice_i) + '.p')\n",
    "try:\n",
    "    ranked_most_quant_0 = list(pickle.load(open(ranked_quant_pickle_savefile, 'rb')))\n",
    "    print(\"Ranked quant phrases for time slice \" + str(timeslice_i) + \" loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load ranked quant phrases for time slice \" + str(timeslice_i))\n",
    "    \n",
    "# Load ranked behavioral and quant words for time slice 0\n",
    "timeslice_i = 19\n",
    "ranked_behavioral_pickle_savefile = output_dir_path / ('ranked_behavioral_for_timeslice_' + str(timeslice_i) + '.p')\n",
    "try:\n",
    "    ranked_most_behavioral_19 = list(pickle.load(open(ranked_behavioral_pickle_savefile, 'rb')))\n",
    "    print(\"Ranked behavioral phrases for time slice \" + str(timeslice_i) + \" loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load ranked behavioral phrases for time slice \" + str(timeslice_i))\n",
    "    \n",
    "ranked_quant_pickle_savefile = output_dir_path / ('ranked_quant_for_timeslice_' + str(timeslice_i) + '.p')\n",
    "try:\n",
    "    ranked_most_quant_19 = list(pickle.load(open(ranked_quant_pickle_savefile, 'rb')))\n",
    "    print(\"Ranked quant phrases for time slice \" + str(timeslice_i) + \" loaded succesfully\")\n",
    "except(IOError):\n",
    "    print(\"Error trying to load ranked quant phrases for time slice \" + str(timeslice_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine most volatile words across time slices (attempt #1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Top 15 words that became more behavioral ***\n",
      "boundary-condition 6078\n",
      "review-helpfulness 5996\n",
      "cognitive-flexibility 5967\n",
      "body-temperature 5904\n",
      "stress-induced 5904\n",
      "product-catalog 5889\n",
      "visual-patterns 5879\n",
      "technological-innovations 5861\n",
      "holidays 5746\n",
      "maximum-coverage 5737\n",
      "initial-state 5726\n",
      "psychological-stress 5726\n",
      "word-completion 5724\n",
      "frequency-distribution 5720\n",
      "moral-emotions 5709\n",
      "\n",
      "*** Top 15 words that became more quant ***\n",
      "assistant-professor 6238\n",
      "washington-dc 6216\n",
      "associate-professor 6213\n",
      "conjoint-analysis 6190\n",
      "complaining 6152\n",
      "consumer-demand 6100\n",
      "british-columbia 6087\n",
      "human-capital 6077\n",
      "utility-function 6066\n",
      "working-paper 6054\n",
      "john-wiley 6030\n",
      "graduate-school 6029\n",
      "business-administration 6026\n",
      "failure-rate 6017\n",
      "yale-university 6000\n",
      "\n",
      "*** Top 15 words that became less behavioral ***\n",
      "yale-university -6006\n",
      "failure-rate -6015\n",
      "john-wiley -6025\n",
      "graduate-school -6029\n",
      "business-administration -6029\n",
      "working-paper -6054\n",
      "utility-function -6066\n",
      "human-capital -6086\n",
      "british-columbia -6091\n",
      "consumer-demand -6098\n",
      "complaining -6149\n",
      "conjoint-analysis -6190\n",
      "associate-professor -6213\n",
      "washington-dc -6215\n",
      "assistant-professor -6237\n",
      "\n",
      "*** Top 15 words that became less quant ***\n",
      "self-control -5811\n",
      "rituals -5826\n",
      "las-vegas -5847\n",
      "technological-innovations -5854\n",
      "self-identity -5866\n",
      "hedonic-consumption -5894\n",
      "brand-value -5912\n",
      "sensory-marketing -5946\n",
      "amazon-mechanical-turk -5953\n",
      "moderation -5980\n",
      "mturk -5985\n",
      "qualtrics -5997\n",
      "prolific -6012\n",
      "moderated-mediation -6042\n",
      "boundary-condition -6170\n"
     ]
    }
   ],
   "source": [
    "phrase_rank_changes = {}\n",
    "for phrase in phrase_list:\n",
    "    # positive number indicates it is ranked higher in period 19 than period 0\n",
    "    behavioral_rank_change = ranked_most_behavioral_0.index(phrase) - ranked_most_behavioral_19.index(phrase)\n",
    "    quant_rank_change = ranked_most_quant_0.index(phrase) - ranked_most_quant_19.index(phrase)\n",
    "    \n",
    "    phrase_rank_changes[phrase] = {\"behavioral-rank-change\": behavioral_rank_change, \"quant-rank-change\": quant_rank_change}\n",
    "    \n",
    "#     print(phrase + \": behavioral rank change \" + str(behavioral_rank_change) + \", quant rank change \" + str(quant_rank_change))\n",
    "\n",
    "# ordered from 'became more behavioral' to 'became less behavioral'\n",
    "ranked_behavioral_change = OrderedDict(sorted(phrase_rank_changes.items(), key=lambda kv: kv[1][\"behavioral-rank-change\"], reverse=True))\n",
    "ranked_quant_change = OrderedDict(sorted(phrase_rank_changes.items(), key=lambda kv: kv[1][\"quant-rank-change\"], reverse=True))\n",
    "\n",
    "top_n = 15\n",
    "print(\"\\n*** Top\", top_n, \"words that became more behavioral ***\")\n",
    "for phrase, rank_change in list(ranked_behavioral_change.items())[:top_n]:\n",
    "    print(phrase, rank_change[\"behavioral-rank-change\"])\n",
    "print(\"\\n*** Top\", top_n, \"words that became more quant ***\")\n",
    "for phrase, rank_change in list(ranked_quant_change.items())[:top_n]:\n",
    "    print(phrase, rank_change[\"quant-rank-change\"])\n",
    "    \n",
    "print(\"\\n*** Top\", top_n, \"words that became less behavioral ***\")\n",
    "for phrase, rank_change in list(ranked_behavioral_change.items())[-1*top_n:]:\n",
    "    print(phrase, rank_change[\"behavioral-rank-change\"])\n",
    "print(\"\\n*** Top\", top_n, \"words that became less quant ***\")\n",
    "for phrase, rank_change in list(ranked_quant_change.items())[-1*top_n:]:\n",
    "    print(phrase, rank_change[\"quant-rank-change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "delete below code later\n",
    "\"\"\"\n",
    "\n",
    "def get_stability(self, w, start_t, end_t, stable_type='avg'):\n",
    "    \"\"\"\n",
    "    code snippet for measuring stability / volatility of words\n",
    "    \"\"\"\n",
    "    total_variations = []\n",
    "    #for y in range(end_t - start_t):\n",
    "    #    total_variation += abs(self.sim_by_word_year(w, y, w, y+1))\n",
    "    N = end_t - start_t\n",
    "    for y1 in range(N):\n",
    "        for y2 in range(y1 + 1, N):\n",
    "            total_variations.append(self.sim_by_word_year(w, y1, w, y2))\n",
    "    \n",
    "    if stable_type == 'avg':\n",
    "        return np.mean(total_variations)\n",
    "    elif stable_type == 'max':\n",
    "        return max(total_variations)\n",
    "    elif stable_type == 'min':\n",
    "        return min(total_variations)\n",
    "    else:\n",
    "        raise ValueError('stable_type should be in [avg, max, min]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine most stable words across time slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
